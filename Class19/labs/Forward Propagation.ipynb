{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Lab -- Forward Propagate A Dataset Built With Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you'll forward propagate using a dataset that contains digits of handwritten digits.  \n",
    "\n",
    "Your neural network will have the following qualities to it:\n",
    "\n",
    " - An input layer\n",
    " - two hidden layers, one with 5 neurons, and one with 10\n",
    " - an output layer that has 10 predicted classes of outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1:  Load in the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/Users/devonbancroft/Desktop/Devon-GA-DAT-10-14/Data/MNIST/processed/X_train.pkl', 'rb') as data:\n",
    "    X_train = pickle.load(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2:  Check the shape of your training images, and look at the first item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3).  Try using the imshow() method in matplotlib to see what the first image looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11c80c470>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try looking at a few more to see what they look like.  Also look at the training labels to see their corresponding identity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x116607c50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/devonbancroft/Desktop/Devon-GA-DAT-10-14/Data/MNIST/processed/y_train.pkl', 'rb') as data:\n",
    "    y_train = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many unique labels are there?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4).  To make this a little bit easier, let's just use the first 100 images of the dataset, so computation doesn't take too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[0:100]\n",
    "y_train = y_train[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize by dividing the training set by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Any idea why we'd do this instead of traditional standardization?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idk, 255 is maximum value. So its % of maximum value. Keeps numbers from 0 to 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5).  Reshape your data so that it's two dimensional:  100X784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(100, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  774  775  776  777  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   778  779  780  781  782  783  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6). Initialize a hidden unit with 10 neurons, as well as a separate set of variables that represent a coefficient for each column in your hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coeff     = np.random.normal(0, 0.1, size=7840).reshape(784, 10)\n",
    "intercept = np.random.normal(0, 0.1, size = 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05690403,  0.28255046,  0.10902056, ...,  0.21115948,\n",
       "         0.2280159 , -0.18044929],\n",
       "       [-0.14288373,  0.08374561, -0.00350527, ..., -0.0587088 ,\n",
       "         0.0406578 , -0.11489162],\n",
       "       [ 0.1507543 , -0.08384082,  0.01746295, ...,  0.06993726,\n",
       "        -0.04683141, -0.06977416],\n",
       "       ...,\n",
       "       [ 0.04583599,  0.12598089,  0.08072213, ..., -0.08236491,\n",
       "        -0.01467741,  0.16442224],\n",
       "       [-0.16477861, -0.16500921,  0.05649829, ..., -0.03766518,\n",
       "        -0.12351664,  0.08416435],\n",
       "       [-0.18690005, -0.10098083, -0.01836575, ...,  0.00138556,\n",
       "         0.03037878, -0.02050662]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7).  Use the dot() method to matrix multiply your input with your layer of hidden weights to create your hidden layer.  Apply the Relu activation function afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hidden = X_train.dot(coeff)+intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hidden = np.maximum(0, X_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hidden.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**check:** The shape of your output should be 100 x 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8:  Initialize another hidden layer with 5 neurons, with the appropriate number of intercept terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff2     = np.random.normal(0, 0.1, size=50).reshape(10, 5)\n",
    "intercept2 = np.random.normal(0, 0.1, size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hidden2 = X_hidden.dot(coeff2)+intercept2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9:  Matrix multiply the output from your last layer, and activate it with ReLu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hidden2 = X_hidden.dot(coeff2)+intercept2\n",
    "X_hidden2 = np.maximum(0, X_hidden2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10:  Create Your Output Layer To Accommodate Each Unique Value in y.  No intercept terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff3     = np.random.normal(0, 0.1, size=50).reshape(5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = X_hidden2.dot(coeff3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 11:  Matrix multiply your last hidden layer with your output layer, and apply the sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = X_hidden2.dot(coeff3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "   return 1/(1+np.exp(-X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(output).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sigmoid(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 12:  Create your prediction by choosing the column in your output layer with the highest overall value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(sigmoid(output)).idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  8\n",
       "2  8\n",
       "3  8\n",
       "4  2"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(predictions).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What Was The Accuracy After Your First Round of Computation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "answers = pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['predictions'] = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers.rename({0:'answer'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 4.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy =\", round(np.mean(answers.answer == answers.predictions) * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x118a305c0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAO+klEQVR4nO3dYWxd9XnH8d9vpBUJLoGJ7m5z0MymKlsVr2tztdEidXZTpqxBbV9UGogiqJj8YmubValYWDX1VbVIW7qibNoUAaMSFp4WMqWDqQW19dAkGs0OdAZC14pmkJTGoAxTs0jU6rMXvoxcY/ten3Ouj5+b70eK4nvO/Z/z+NG5vxwfn/+JI0IAgHx+ru4CAADFEOAAkBQBDgBJEeAAkBQBDgBJbVrPnV111VUxNDRUaOxrr72myy67rNqCEqMfb6IX7ehHu37ox/T09MsR8c6ly9c1wIeGhjQ1NVVo7OTkpEZGRqotKDH68SZ60Y5+tOuHftj+7+WWcwkFAJIiwAEgKQIcAJIiwAEgKQIcAJIiwAEgqY4Bbvte27O2n1pm3edth+2relMeAGAl3ZyB3ydp99KFtq+WdL2k5yuuCQDQhY4BHhGPSTq3zKq/lnSHJB4oDgA1KDQT0/ZHJZ2JiO/a7vTeMUljktRoNDQ5OVlkl5qfny88tqyZM3O17Hd4cOuK6+rsx0ZDL9rRj3b93I81B7jtLZK+IOn3unl/RByWdFiSms1mFJ3SWud02Nv2P1zLfk/dPLLiun6YHlwVetGOfrTr534UuQvl1yRdI+m7tk9J2ibphO1frLIwAMDq1nwGHhEzkn7hjdetEG9GxMsV1gUA6KCb2wgfkPS4pO22T9u+vfdlAQA66XgGHhE3dVg/VFk1AICuMRMTAJIiwAEgKQIcAJIiwAEgKQIcAJIiwAEgKQIcAJIiwAEgKQIcAJIq9DjZOsycmavtqYAAsBFxBg4ASRHgAJAUAQ4ASRHgAJAUAQ4ASRHgAJAUAQ4ASRHgAJAUAQ4ASRHgAJBUN/8r/b22Z20/dcGyv7T9rO3/tP3Ptq/obZkAgKW6OQO/T9LuJcselbQjIn5T0n9JurPiugAAHXQM8Ih4TNK5JcseiYiF1svvSNrWg9oAAKtwRHR+kz0k6aGI2LHMun+R9I8Rcf8KY8ckjUlSo9HYOTExUajQ2XNzOnu+0NC0hge3rrhufn5eAwMD61jNxkUv2tGPdv3Qj9HR0emIaC5dXupxsra/IGlB0vhK74mIw5IOS1Kz2YyRkZFC+zo0fkwHZ9I8/bYSp24eWXHd5OSkivay39CLdvSjXT/3o3Ai2r5V0g2SdkU3p/EAgEoVCnDbuyX9qaTfjYj/rbYkAEA3urmN8AFJj0vabvu07dsl/Y2kd0h61PaTtv++x3UCAJboeAYeETcts/ieHtQCAFgDZmICQFIEOAAkRYADQFIEOAAkRYADQFIEOAAkRYADQFIEOAAkRYADQFIX1+P90JWh/Q/XXcKa7Bte0G0laz51YE9F1axd1f3uth91fs91qfPY7kW/OQMHgKQIcABIigAHgKQIcABIigAHgKQIcABIigAHgKQIcABIigAHgKQIcABIigAHgKQ6Brjte23P2n7qgmU/b/tR299v/X1lb8sEACzVzRn4fZJ2L1m2X9I3I+Jdkr7Zeg0AWEcdAzwiHpN0bsnij0n6auvrr0r6eMV1AQA6cER0fpM9JOmhiNjRev1KRFxxwfr/iYhlL6PYHpM0JkmNRmPnxMREoUJnz83p7PlCQ9MaHty64rr5+XkNDAz0ZL8zZ+Z6st1eaWxW6WNjtV73WtX9rqIfvbae/b7ws1LnsV3mex4dHZ2OiObS5T1/HnhEHJZ0WJKazWaMjIwU2s6h8WM6OHNxPb781M0jK66bnJxU0V52UvbZ2utt3/BC6WNjtV73WtX9rqIfvbae/b7ws1Lnsd2L77noXShnbf+SJLX+nq2uJABAN4oG+Nck3dr6+lZJx6opBwDQrW5uI3xA0uOStts+bft2SQckXW/7+5Kub70GAKyjjhfKIuKmFVbtqrgWAMAaMBMTAJIiwAEgKQIcAJIiwAEgKQIcAJIiwAEgKQIcAJIiwAEgKQIcAJIiwAEgKQIcAJIiwAEgKQIcAJIiwAEgKQIcAJIiwAEgKQIcAJIiwAEgKQIcAJIiwAEgqVIBbvtztp+2/ZTtB2xfWlVhAIDVFQ5w24OSPiupGRE7JF0i6caqCgMArK7sJZRNkjbb3iRpi6QflS8JANANR0TxwfZeSV+SdF7SIxFx8zLvGZM0JkmNRmPnxMREoX3NnpvT2fOFS01peHDriuvm5+c1MDDQk/3OnJnryXZ7pbFZpY+N1Xrda1X3u4p+9JON0o8yx9jo6Oh0RDSXLi8c4LavlPSgpD+Q9Iqkf5J0JCLuX2lMs9mMqampQvs7NH5MB2c2FRqb1akDe1ZcNzk5qZGRkZ7sd2j/wz3Zbq/sG14ofWys1uteq7rfVfSjn2yUfpQ5xmwvG+BlLqF8WNIPI+KliPippKOSPlBiewCANSgT4M9Lutb2FtuWtEvSyWrKAgB0UjjAI+K4pCOSTkiaaW3rcEV1AQA6KHVhKCK+KOmLFdUCAFgDZmICQFIEOAAkRYADQFIEOAAkRYADQFIEOAAkRYADQFIEOAAkRYADQFIEOAAkRYADQFIEOAAkRYADQFIEOAAkRYADQFIEOAAkRYADQFIEOAAkRYADQFIEOAAkRYADQFKlAtz2FbaP2H7W9knb76+qMADA6jaVHH+XpK9HxCdsv13SlgpqAgB0oXCA275c0gcl3SZJEfG6pNerKQsA0IkjothA+7ckHZb0jKT3SJqWtDciXlvyvjFJY5LUaDR2TkxMFNrf7Lk5nT1faGhfamwW/WipohfDg1urKaaAmTNzlW6PY6PdRulHmWNsdHR0OiKaS5eXCfCmpO9Iui4ijtu+S9KrEfHnK41pNpsxNTVVaH+Hxo/p4EzZKz79Y9/wAv1oqaIXpw7sqaiatRva/3Cl2+PYaLdR+lHmGLO9bICX+SXmaUmnI+J46/URSe8rsT0AwBoUDvCI+LGkF2xvby3apcXLKQCAdVD254rPSBpv3YHynKRPlS8JANCNUgEeEU9Kest1GQBA7zETEwCSIsABICkCHACSIsABICkCHACSIsABICkCHACSIsABICkCHACSqv8RXcAGUPUTAYH1wBk4ACRFgANAUgQ4ACRFgANAUgQ4ACRFgANAUgQ4ACRFgANAUgQ4ACRFgANAUqUD3PYltp+w/VAVBQEAulPFGfheSScr2A4AYA1KBbjtbZL2SLq7mnIAAN0qewb+FUl3SPpZBbUAANbAEVFsoH2DpI9ExB/ZHpH0+Yi4YZn3jUkak6RGo7FzYmKi0P5mz83p7PlCQ/tSY7PoRwu9aEc/2m2UfgwPbi08dnR0dDoimkuXlwnwv5B0i6QFSZdKulzS0Yj45Epjms1mTE1NFdrfofFjOjjD48vfsG94gX600It29KPdRunHqQN7Co+1vWyAF76EEhF3RsS2iBiSdKOkb60W3gCAanEfOAAkVcnPFRExKWmyim0BALrDGTgAJEWAA0BSBDgAJEWAA0BSBDgAJEWAA0BSBDgAJEWAA0BSBDgAJEWAA0BSBDgAJEWAA0BSBDgAJEWAA0BSBDgAJEWAA0BSBDgAJEWAA0BSBDgAJEWAA0BSBDgAJFU4wG1fbfvbtk/aftr23ioLAwCsblOJsQuS9kXECdvvkDRt+9GIeKai2gAAqyh8Bh4RL0bEidbXP5F0UtJgVYUBAFbniCi/EXtI0mOSdkTEq0vWjUkak6RGo7FzYmKi0D5mz83p7PlydfaTxmbRjxZ60Y5+tNso/Rge3Fp47Ojo6HRENJcuLx3gtgck/ZukL0XE0dXe22w2Y2pqqtB+Do0f08GZMld8+su+4QX60UIv2tGPdhulH6cO7Ck81vayAV7qLhTbb5P0oKTxTuENAKhWmbtQLOkeSScj4svVlQQA6EaZM/DrJN0i6UO2n2z9+UhFdQEAOih8YSgi/l2SK6wFALAGzMQEgKQIcABIigAHgKQIcABIigAHgKQIcABIigAHgKQIcABIigAHgKQIcABIigAHgKQIcABIigAHgKQIcABIigAHgKQIcABIigAHgKQIcABIigAHgKQIcABIigAHgKRKBbjt3ba/Z/sHtvdXVRQAoLPCAW77Ekl/K+n3Jb1b0k22311VYQCA1ZU5A/9tST+IiOci4nVJE5I+Vk1ZAIBOHBHFBtqfkLQ7Iv6w9foWSb8TEZ9e8r4xSWOtl9slfa9grVdJerng2H5EP95EL9rRj3b90I9fiYh3Ll24qcQGvcyyt/xrEBGHJR0usZ/FndlTEdEsu51+QT/eRC/a0Y92/dyPMpdQTku6+oLX2yT9qFw5AIBulQnw/5D0LtvX2H67pBslfa2asgAAnRS+hBIRC7Y/Lekbki6RdG9EPF1ZZW9V+jJMn6Efb6IX7ehHu77tR+FfYgIA6sVMTABIigAHgKRSBDhT9hfZvtr2t22ftP207b1117QR2L7E9hO2H6q7lrrZvsL2EdvPto6T99ddU11sf671OXnK9gO2L627pqpt+ABnyn6bBUn7IuI3JF0r6Y8v4l5caK+kk3UXsUHcJenrEfHrkt6ji7QvtgclfVZSMyJ2aPFGixvrrap6Gz7AxZT9/xcRL0bEidbXP9Hih3Ow3qrqZXubpD2S7q67lrrZvlzSByXdI0kR8XpEvFJvVbXaJGmz7U2StqgP56lkCPBBSS9c8Pq0LvLQkiTbQ5LeK+l4vZXU7iuS7pD0s7oL2QB+VdJLkv6hdUnpbtuX1V1UHSLijKS/kvS8pBclzUXEI/VWVb0MAd7VlP2Lie0BSQ9K+pOIeLXueupi+wZJsxExXXctG8QmSe+T9HcR8V5Jr0m6KH9nZPtKLf6kfo2kX5Z0me1P1ltV9TIEOFP2L2D7bVoM7/GIOFp3PTW7TtJHbZ/S4qW1D9m+v96SanVa0umIeOOnsiNaDPSL0Ycl/TAiXoqIn0o6KukDNddUuQwBzpT9FtvW4vXNkxHx5brrqVtE3BkR2yJiSIvHxbciou/OsroVET+W9ILt7a1FuyQ9U2NJdXpe0rW2t7Q+N7vUh7/QLfM0wnVRw5T9jew6SbdImrH9ZGvZn0XEv9ZYEzaWz0gab53sPCfpUzXXU4uIOG77iKQTWrx76wn14ZR6ptIDQFIZLqEAAJZBgANAUgQ4ACRFgANAUgQ4ACRFgANAUgQ4ACT1f6Z4IeM1zTbkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "answers.answer.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    14\n",
       "0    13\n",
       "9    11\n",
       "6    11\n",
       "4    11\n",
       "3    11\n",
       "7    10\n",
       "8     8\n",
       "2     6\n",
       "5     5\n",
       "Name: answer, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.answer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x118aa4e10>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "answers.predictions.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8    41\n",
       "2    35\n",
       "0    11\n",
       "7     6\n",
       "9     5\n",
       "4     2\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.predictions.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(answers.predictions.isin([8, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus:  Create Your Own Functions Called `forward` and `predict` that codify what you did in this lab, where you can specify how many neurons to use for each hidden layer, and make a corresponding prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-aecbd7e7fc3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m model = keras.Sequential([\n\u001b[1;32m      5\u001b[0m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(5, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.sigmoid)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-8706f6fbfb3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.compile(optimizer='sgd', \n\u001b[0m\u001b[1;32m      2\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m               metrics=['accuracy'])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='sgd', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
